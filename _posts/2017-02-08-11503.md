---
layout: post
title: 机器学习专家与统计学家观点上有哪些不同？
published: true
author: admin
comments: false
date: 2017-02-08 09:02:36
tags: [ ]
categories: [ ]
permalink: "11503"
---
**经典统计和机器学习分别在哪些领域有优势？**
  
在一些传统领域，工程实验，生物试验，社会调查，物理实验，我们能获得的**数据量非常小**，我们必须小心翼翼的对待我们的模型，从有限的数据中提取尽量可能多的信息。抑或是一些对参数很敏感的预测，差之毫厘失之千里，比如检验一个艾滋病新药物是否有效，来决定要不要投入funding去进行研发，我们就要用**严谨的概率统计模型**。
  
但是在搜索引擎，淘宝用户购买信息，人脸特征识别等领域，我们**能够获得很大量的数据**，而且数据维度也非常高，用传统方式建模，很有可能维度高到严谨的function根本解不出来，**机器学习的理论**就非常有效了。

**共同点**：统计建模或者机器建模的目的都是从数据中挖掘到感兴趣的信息。下面只讨论supervised learning， 就是对一个pair: ( 自变量x，因变量y）进行建模。 也就是找到一个函数 y=f(x) ， 用x 来刻画 （解释、预测）y。 首先我们要一组观察值（x,y），来 回归（learn）这个未知的函数 f.

**区别：**

**统计学家：** 在刻画 f 的过程中，统计学家用的方法是： 对于 f 的形状和 y 的random distribution 进行一些假设。 比如说假设 f 是线性模型， 或者y 是normal distribution。 然后来求在一定标准下最优的 f. 比如说，在BLUE （Best Linear Unbiased Estimators）的标准下，最小二乘估计出来的 f 就是最好的估计。 然后根据对数据的distribution的假设或者是大数定律，可以求出 参数估计的不确定性 或者是 standard error。 进而构建置信区间，来表达我对我能做出的 f 的最好的估计 的信心。优点： 可以对不确定性度量。 简单模型的可解释性强。当假设的assumptions满足时模型科学、准确、严谨。 缺点：复杂情况下assumptions难以验证。

**机器学习专家：**不对 y 的distribution进行过多的假设，不计算standar error，不 care bias。 通过 cross validation来判断 对于 f 的估计的好坏。 也就是说，在机器学习领域，数据量大，机器学习专家拿一部分来估计（train，learn ）f，留一部分来验证预测结果的好坏。预测结果好的模型就是好模型，不计算估计参数的偏差。 缺点： 缺乏科学严谨性。 优点： 简单粗暴。 有一次听一个大牛的seminar几个教授的段子记忆尤新：**&#8220;those machine learning people are making predictions without probability! &#8220;。**

对于这句话：“**统计学家更关心模型的可解释性，而机器学习专家更关心模型的预测能力” ：** 总体来说**，可解释性强的模型会损失预测能力，预测能力强的模型往往比较难解释。 常见的模型中，从可解释性强到预测强的模型依顺序排列是**
  
1 Lasso+线性回归
  
2 线性回归
  
3 非线性模型
  
4 非参模型
  
5 SVM
  
构建简单的模型，比如线性模型，更容易解释因变量对自变量的影响。 适合于那种目的是解释一个变量对另外一个变量的影响的问题。也是经典统计中最常用到的模型。变化再多一些，非线性模型，非参模型，更灵活，选择更多，所以可能达到更好的预测效果。但是往往比较难解释x对y的影响。（**这些模型都来源于统计，推广于机器学习。这些模型都是几十年前统计的研究成果了好么！！因为最近计算机速度提上来了，原来没名气，是因为计算速度带不动，数据没收集辣么多啊！！）！**因为机器学习领域的数据大，运算能力强，所以能把复杂的非参或者非线性模型用的效果比较好。
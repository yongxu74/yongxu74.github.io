---
layout: post
title: >
    欧盟要求「解释权」，或引发与人工智能公司的冲突
published: true
author: admin
comments: false
date: 2016-07-18 09:07:15
tags: [ ]
categories: [ ]
permalink: "9905"
---
 

神经网络正在改变互联网。受到人脑内部神经网络的启发而构建出的深度数学模型，能通过分析大量数据而学会完成各种独立的任务。这些模型学会了识别照片中的人脸、辨认语音指令和翻译文本。而这仅仅是开始。它们还进入谷歌和 Facebook 等科技巨头的核心业务。当你使用谷歌搜索引擎或浏览 Facebook 动态消息时，它们帮助筛选你看到的信息。

所有这些都在塑造着网络服务行为。但是这对世界上最大的网络市场欧盟而言还意味着思想交锋的蓄势待发。

在四月份，欧盟为个人信息（包括网上数据）的收集、存储和使用制定了新的规则。这套规则名叫「全球数据保护法规 (General Data Protection Regulation, GDPR )」 ，它经历了十年酝酿，而且将在 2018 年开始生效。即使欧盟以外地区的公司收集各种数据，它也能保护欧盟公民的数据安全。它授予欧盟惩罚违反条规的公司的权力，可罚款 2 千万欧元或公司全球收入的 4% 。

但这不是全部。从官方言论透露出的措施指令表明，GDPR 也限制欧盟所谓的「自动化个人决策 (automated individual decision-making) 」。而对于世界上最大的科技公司，这是一个潜在问题。「自动化个人决策」是神经网络要做的事情。牛津大学的哲学家和社会科学研究者 Bryce Goodman 说：「他们正在谈论机器学习。」他和牛津大学的一位研究者同事最近发表了一篇探讨这些新规定潜在影响的论文：（见原文链接）

难以解释

这些规定禁止任何「显著影响（significantly affects）」欧盟公民的自动化决策。这包括评估个人「工作表现、经济条件、健康、个人偏好、兴趣、可靠度、行为、地理位置或活动」的技术。同时，法律提供了 Goodman 所谓的「解释权（right to explanation）」。换言之，条规让欧盟公民可以检查特定服务是如何做出某种特定的算法决策的。

这些规定都会冲击大多数网络服务的核心。例如，在 Facebook ，机器学习系统已经在推动广告精准投放，而这依赖于非常多的个人信息。另外，机器学习本身并不能完全服从「解释权」。甚至对专家而言，解释神经网络内部发生了什么也是一项复杂任务。神经网络通过分析数百万数据进行运作，尽管这些系统工作得非常好，但是也很难确切地弄清楚它们为什么工作得如此之好。你不可能轻易地追踪它们精确的工作路径从而找到答案。牛津大学互联网管理专家 Viktor Mayer-Schönberger 曾参与草拟了部分新规，他说 GDPR 对自动化决策的描述可有不同的解读方式。但是他最近说，「一个重大问题」是语言如何影响深度神经网络。深度神经网络依赖于海量数据，而且它们产生的复杂算法甚至可能对开发应用这些系统的人而言都是深奥难懂的。Mayer-Schönberger 说：「就这两方面来看，GDPR 有话要说。」

## 准备冲突

一方面，Goodman 相信这些规定击痛了 Facebook 商业模式的核心。他说：「法律牢牢紧盯着大型跨国公司。」Facebook 没有对外界就此问题作评论的要求做出回应，但是局势的紧张是显而易见的。公司每年都在精准投放广告上赚取数十亿美元，现在它又在用机器学习技术来赚钱了。所有迹象表明，谷歌也在将神经网络应用于广告投放，就像应用于「有机的（organic）」搜索结果一样。谷歌也没有对外界相关要求做出回应。

## 神经网络本身难以进行简单的解释，这极可能会导致某些不可避免的冲突。

但是，Goodman 并不只是将矛头对准了互联网大公司。机器学习的最新发展像流水一样从特大型企业渗透到其余互联网企业。他说，欧盟的新规可能影响所有事物的进程，从普通的网络推荐引擎到信用卡和保险公司。

Mayer-Schönberger 说，欧洲法院可能最终会发现，神经网络不只是自动化决策，它们更多还是统计分析。然而即使那样，科技公司还是会卷入「解释权」的纠纷。他解释到，深度神经网络的美丽之处部分在于它们是「黑箱」。它们以超越人类逻辑之外的方式工作，这意味着来年采用这种技术的无数企业将因欧盟新规要求给出神经网络工作方式的解释而陷入麻烦。

「做出解释不是不可能，」神经网络创业公司 Skymind 的 CEO 和创始人 Chris Nicholson 说，「但是这很复杂。」

## 人类干预

解决这种难题的一种途径是让人类决策者干预或控制自动化算法。在许多情况下，这是可能发生的，因为许多设备在人类制定的明确规则下协调运用了机器学习和其它技术。这就是谷歌搜索引擎的工作方式。Nicholson 说：「在很多时候，算法只是解决方案（需要人类参与的方案）的一部分。」

但是，互联网趋于更加自动化，而不会更少。所以最后，人为干预不一定是最佳答案。「人类真是糟糕透了。」一位评论员在科技讨论网站 Hacker News 上写到，「我们不可思议地带有偏见。」

由欧盟新规带来的难题将不只是影响最大的科技公司，也将延伸到所有事物上。

这是一场公正的争论。只有当机器学习继续进步，它才将会变得更加公正。人们倾向于将自己的信念施加给机器，但是机器正变得越来越重要。接下来要讨论的无人驾驶汽车的伦理问题也是同样充满剑拔弩张的紧张。一些人说：「我们不能让机器做道德决策。」但是其他人说：「当你看到道路更加安全时，你就会改变想法。」机器永远不会成为人类。但是，在一些情况下，它们可能比人类做得更好。

## 数据保护之外

归根结底，正如 Goodman 推断的那样，由欧盟新规带来的难题将延伸到一切事物上。不管需要完成的任务是生成搜索结果、道路导航、以股票进行交易还是寻找浪漫的伴侣，机器学习都是未来的发展道路。谷歌如今的使命是再次培训员工，让他们适应新的世界秩序。Facebook 提供各种工具，可以让公司内的任何人利用机器学习的力量。谷歌、微软和亚马逊如今通过它们的云计算服务给全世界其它公司提供机器学习技术。

GDPR 应对的是数据保护问题。但是这只是潜在冲突的一个方面。例如，反托拉斯法将如何对待机器学习？ 谷歌现在面临的情况是被指控在它的搜索结果中差别对待某些竞争对手。但是这种情况几年前就被提出来了。当公司们抱怨机器存在歧视时，又将发生什么呢？

「驳斥这种论点变得更加困难，」Mayer-Schönbergerd 说，因为甚至谷歌也可能无法解释神经网络是如何做出决策的。本文选自：Wired，作者：CADE METZ，机器之心编译；
---
layout: post
title: 2018年，人工智能将为这五个难题绞尽脑汁
published: true
author: admin
comments: false
date: 2017-12-29 03:12:34
tags: [ ]
categories:
    - uncategorized
permalink: "13510"
---
就大量关于“杀手级机器人”的炒作来说，2017年在人工智能方面取得了一些显著的进步。阿尔法狗、冷扑大师等棋牌机器人能让顶级玩家陷入绝望，在现实世界中，机器学习正被用于改善农业，以及扩大医疗保健的覆盖面。

但你最近和Siri或者Alexa对话过吗？如果有，那么你会知道，撇开这些炒作，以及踌躇满志的亿万富翁们，还有很多事情人工智能仍然不能做也不能理解。以下是五个棘手的问题，专家们将在明年为它们绞尽脑汁。请看雷锋网为您一一道来：

![]()

### 语言真正的含义

在处理文本和语言方面，机器比以往任何时候都做的更好。 Facebook可以为视障人士读出图像描述。谷歌做了一个很不错的软件，能在回复电子邮件时给出简短的建议。然而，软件仍然不能真正理解我们的话语的含义，或我们想与它们分享的想法。波特兰州立大学教授梅兰妮·米切尔（Melanie Mitchell）表示：“人类能够把我们学到的概念以不同的方式结合起来，并在新的情况下应用。AI和机器学习系统则不能。”

Mitchell将今天的软件面临的问题描述为数学家Gian Carlo-Rota所说的“意义障碍”。一些领先的AI研究团队正试图找出克服它的方法。

这项工作的一部分，旨在为机器提供关于常识和实体世界的认知基础——它们奠定了我们的思维。例如，Facebook研究人员正通过观看视频来教软件理解现实。还有人在模拟我们可以用关于世界的知识做些什么。谷歌一直在试图打造能够理解隐喻的软件。米切尔实验过一种系统，使用类比和概念存储来解释照片中发生的事情。

### 阻碍机器革命的“现实差距”

机器人硬件已经发展的相当不错了。花500美元，你就能购买携带高清摄像机的手掌大小的无人机。搬运箱子的机器人以及两条腿走路的机器人也有所改进。那为什么我们还没有被繁忙的机械助手所包围？因为现在的机器人缺乏能够匹配他们先进的肌肉的大脑。

让机器人做任何事情都需要针对特定的任务进行特定的编程。它们可以通过重复的试验（和错误）学习操作，如抓取物体。但是这个过程相对较慢。一个有希望的捷径是让机器人在虚拟的、模拟的世界中训练，然后把那些来之不易的知识下载到实体机器人体内。然而，这种方法被现实差距所困扰，具体来说，机器人在模拟过程中学到的技能，在转移到实体世界中的机器时，并不总是有效。

这种现实差距正在缩小。十月，在虚拟和真实的机器人手臂拾取多种物品的实验中——这些任务包括胶带分配器，玩具和梳子等等——谷歌报告了可喜的结果。

对于自动驾驶汽车从业者来说，取得进一步的进步很重要。在机器驾驶竞赛中，众多公司在在虚拟街道上部署虚拟车辆，他们希望能减少在实际交通和道路条件下测试所花费的时间和金钱。自动驾驶创业公司Aurora首席执行官Chris Urmson说，使虚拟测试更适用于真实车辆是团队的优先考虑之一。曾经领导谷歌母公司Alphabet的自主汽车项目的Urmson说：“明年或以后，我们可以利用这种技术来加速学习。”

### 防范AI黑客攻击

运行电网，安全摄像头和手机的软件时常受到安全漏洞的困扰。自动驾驶汽车和家用机器人的软件想必也不会例外。事实上它们的情况可能更糟糕：有证据表明，机器学习软件的复杂性引发了新的攻击途径。

研究人员今年表示，你可以在机器学习系统内部隐藏一个秘密触发器，让它在一个特定的信号下转为恶性模式。纽约大学的研究小组设计了一个街道识别系统，该系统看到黄色的便利贴就会停止正常工作。将一张便利贴贴在布鲁克林的停车标志上，会导致系统将该标志报告为限速。这些把戏的潜在可能性可能会给成自动驾驶汽车造成问题。

这个威胁很严重，本月早些时候，世界顶级机器学习会议的研究人员召开了一个关于“机器骗术的威胁”的研讨会。研究人员讨论了一些恶魔般的骗术，比如生成一些在人类看来很正常、但是对软件来说意味却截然不同的手写数字。例如，你所看到的是一个2，而机器视觉系统看到的是一个3。研究人员还讨论了这种攻击的可能防御方法，并且担心人工智能被用来愚弄人类。

组织研讨会的Tim Hwang预测，随着机器学习变得更容易部署，功能更强大，使用该技术操纵人是不可避免的。他说：“你不再需要一房间的博士才能研究机器学习。”黄指出，在2016年总统选举期间，俄罗斯的虚假宣传运动是潜在的AI加持的信息战的先行者。他说：“为什么从机器学习的领域看看这些活动中涉及到的科技呢？” Hwang预测，其中一个格外有效的骗术可能是使用机器学习制造虚假的视频和音频。

### 超越桌游

Alphabet的国际象棋冠军阿尔法狗软件在2017年迅速崛起。五月份，一个更强大的版本击败了中国的围棋冠军柯洁。它的创造者，研究机构DeepMind，随后构建了一个新的版本，AlphaGo Zero，不通过研究人类棋术而直接学习围棋。十二月， AlphaZero又一次升级，它可以学习下围棋和日本棋类游戏Shogi（虽然不是在同时）。

![]()

这种滚雪球般的捷报令人印象深刻，但同时也提醒人们AI软件的局限性。国际象棋，shogi和围棋都很复杂，但规则相对简单，且对手的玩法清晰可见。它们与计算机能迅速掌握的许多未来职位的能力非常匹配。但是生活中的大多数情况和问题，并不是这样结构整齐。

因此在2017年，DeepMind和Facebook都开始在多人游戏“星际争霸”上下功夫。现在两者的进展都不大。目前最好的机器人是业余爱好者所建立的——即使是与中等技能的玩家相比，它们也无法匹敌。今年早些时候，DeepMind研究员Oriol Vinyals曾表示，需要缺乏规划和记忆能力才能精心组装和指挥一支军队，同时期预测并对对手的动作做出反应，而他的软件缺乏这种能力。无独有偶，这些技能对于软件更好地帮助实际工作也至关重要，如办公室工作或真正的军事行动。 2018年“星际争霸”或类似游戏的巨大进步可能预示着人工智能的一些强大的新应用。

### 教AI辨别是非

即使没有在上述领域取得新的进展，如果现有的AI技术被广泛采用，经济和社会的许多方面也会发生很大的变化。企业和政府正急于这样做，与此同时，有人对人工智能和机器学习可能造成的意外和故意伤害表示担忧。

在本月的NIPS机器学习大会上，一个重要的讨论话题是，如何使技术保持在安全和道德的范围内。研究人员发现，我们的世界本身远不完美，机器学习系统从中获得训练数据，因而可能学会令人不愉快或者我们不期望的行为，如延续性别偏见和刻板印象。现在有人正在研究技术，用于审核人工智能系统内部运作，确保他们在投入金融或医疗保健等行业工作时作出公平的决策。

![]()

明年我们应该会看到科技公司提出相关理念，关于如何让人工智能站在人性光明面。谷歌，Facebook，微软和其他人已经开始讨论这个问题，以及一个新的名叫“Partnership on AI”的非营利组织的成员，该组织将研究和尝试塑造人工智能的社会影响。更多的独立组织也感受到了压力。一个名为“人工智能伦理与治理基金会”的慈善项目正在支持麻省理工学院、哈佛大学等研究人工智能和公共利益。纽约大学的一个新研究机构AI Now也有类似的任务。在最近的一份报告中，它呼吁各国政府发誓放弃在刑事司法或福利等领域使用没有公开检查的“黑匣子”算法。